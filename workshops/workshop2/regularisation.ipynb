{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammoss/MLiS2/blob/master/workshops/workshop2/regularisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9lgu7n44eFs"
      },
      "source": [
        "**Regularisation**\n",
        "\n",
        "In this example you are given a dataset (MNIST) with a limited number of training examples (only 1000 compared to the usual 60,000). \n",
        "\n",
        "Your goal is to implement regularisation methods to achive the **lowest possible test loss using this dataset**. \n",
        "\n",
        "You should consider methods given in the lectures including:\n",
        "\n",
        "*   Data augmentation\n",
        "*   Early stopping\n",
        "*   L1/L2 penalty norms\n",
        "*   Dropout\n",
        "\n",
        "You are free to change the network architecture and model complexity, but the main purpose of the workshop is to investigate regularisation (next week you will look at CNN architectures in detail). \n",
        "\n",
        "You are also free to change the choice of optimiser, and other hyper-parameters such as the batch size.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "cNviuTwum6vs"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "ARZRYjHQnE-0"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import Model, regularizers\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "7I-MxTxAnH2d"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxO576eJnMXN",
        "outputId": "b8ef8e05-86a5-4681-fda5-7406c20ec7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.17.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4F_HTQpnvSk"
      },
      "source": [
        "First load the MNIST dataset and add a channels dimension (channels last convention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "Twdc-t9FnN_9"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train[..., tf.newaxis].astype(np.float32)\n",
        "x_test = x_test[..., tf.newaxis].astype(np.float32)\n",
        "\n",
        "img_rows = x_train.shape[1]\n",
        "img_cols = x_train.shape[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEsWYkNz5Po7"
      },
      "source": [
        "Let's use a much smaller training dataset of 1000 examples so overfitting is more problematic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzt-HoIo4yks",
        "outputId": "fa29683d-8787-4e57-bd38-1b5386df1467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "n_train = 1000\n",
        "x_train = x_train[0:n_train, :]\n",
        "y_train = y_train[0:n_train]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "x2JSWYGKjsPh"
      },
      "outputs": [],
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(15, 15))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(np.squeeze(img))\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDfQh4AfoBAH"
      },
      "source": [
        "Let's visualise several training examples - to do this we use the keras ImageDataGenerator. We rescale images by 1/255 to normalise them in the range (0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "fuOz9BopjZPq",
        "outputId": "45df3d4a-e467-44ee-ee38-62ea5fdf4bb3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABdIAAAEtCAYAAAAMfZJ4AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGZBJREFUeJzt2nuYnWVh7uFvZlaYSQIJIYkJEGICyUBQQc4wFoEqUAQpFZBmCyh4IAiIVET3LuDutuAuEQhyvARUpNLWKsEgVlELgs2B86GgJIGggXAQCBAEkszM6h9erd0X8O6HzBrWTOa+//75fu81Mos1D19LvV6vVwAAAAAAwOtqbfYFAAAAAABgIDOkAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFtTTct/Xw/rwHQPXT3n9e5/+tzyigv/mMAgYyn1HAQOYzChjI0s8ob6QDAAAAAECBIR0AAAAAAAoM6QAAAAAAUGBIBwAAAACAAkM6AAAAAAAUGNIBAAAAAKDAkA4AAAAAAAWGdAAAAAAAKDCkAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFhnQAAAAAACgwpAMAAAAAQIEhHQAAAAAACgzpAAAAAABQYEgHAAAAAIACQzoAAAAAABQY0gEAAAAAoMCQDgAAAAAABYZ0AAAAAAAoMKQDAAAAAECBIR0AAAAAAAoM6QAAAAAAUGBIBwAAAACAAkM6AAAAAAAUGNIBAAAAAKDAkA4AAAAAAAWGdAAAAAAAKDCkAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFtWZfAFIrTuuKujM+8Z2oO3Tkyr5c5zVmLts36n735anxmRv85I51vQ4AAAAA0CDeSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFhnQAAAAAACgwpAMAAAAAQIEhHQAAAAAACgzpAAAAAABQYEgHAAAAAICCWrMvAD177xh1M4/8edSNan016i5/YYuoS31i4i1Rt+MV8+IzD/30KVHXcf1t8ZkAJa3v3CZuN7visaj7+hbZ5+MHDv1Y9uCF92UdMGj85m+6ou5nx5wTn/nlJ/eNukd3fSU+EwCAocsb6QAAAAAAUGBIBwAAAACAAkM6AAAAAAAUGNIBAAAAAKDAkA4AAAAAAAWGdAAAAAAAKDCkAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBQa/YFoO3mu6Lu5lm7R92//WarqOt+fEXUtY4cGXWjb9w66vaZ8tOoq6qq2vyLS6Lu2evjI4Ehqm38+Kjb758WxmeesPHDUbdwdUvUtT33+6jriSqgP7V2dETdk5/YMer+8ejzo26j1raoq6qqum/O9lE3qso/9wCA9UfrdttE3VPvGRN1ux97d9T11LO/j1L3PbtZ1D2/aEJ85pRz74+63lWr4jPXB95IBwAAAACAAkM6AAAAAAAUGNIBAAAAAKDAkA4AAAAAAAWGdAAAAAAAKDCkAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgIJasy8AqZb590Zdd4Of+7u/3C7q5k25qMFPrqpFi7aOumnVwoY/GxgcaptOjLqJc1+KuhM2fjh+9hM9r0Td0fNOjbppi32WMfDUu7aPuvR7yvqideLbom7h/7wgPTGqtr1pVnheVU27xmcKg9fa9+8Udb/bsT3q1mxUj7qHPn5p1M1ZOSXqHnhp86hb+P3sszbV0pN1m547v6HPBfrZru+KsmV/1RJ189+TfeaNbu2IutYqe25vlX0mx7KP2qp1u+x+VVVVM9+/b9Q98KOuqJt09vrxeeuNdAAAAAAAKDCkAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFhnQAAAAAACgwpAMAAAAAQEGt2ReAZln5sT2i7tovzQ5PHB5Vhy49MDyvqrb+3w9GXU98IjBYrDpi96j71jnnRt1Wtewzqjeq/uDAC0+Lummz57+JU+Gt0bvnDlE35+pLou7P5x8fdVv9j3uibqB78IsTG3recz2ro26bM56Lz+xe18vwlllyQfbvuq2+l/3zsfV52Xfn9ta1UddM+4/+dtTtM/zVhj53bT3rTtj44SxMu5NvybrQC73Zz+XoeUdFXc+SR/pyHRiy6ntsH3Ur9hoZdbee8NWo27C1PeqqqiPsGmvW8r2irmv00qg7etTjfbnO6/rO1Buj7uVP/zDq3j355KjrnHVb1DWLN9IBAAAAAKDAkA4AAAAAAAWGdAAAAAAAKDCkAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgoNbsC0Cqbfz4qHv64GlRd+2XZkfdpm3Do27p2tVR98LsyVFXVVXV8eJtcQsMDmv32znq9v1ft0bd1FpHX67zGjufc1Lcbn7JHVFXX9fLQD9a8dk1UTdtWPZ1+dh3Loi6X1TZ94pm+f2hu0XdPQfNCU/Mfn4HfPW0qJuwbH74XJpp9YG7RN23PnhZ1O1xWE9frsMQNLo1+37U9f0Ho27+h2ZEXc/SZVEHg13LLu+Kupnf/JeoO2qjJ6OurWVE1L3cm33P+/tVU6JuzjWHRN0WX86+p7QMy+73lav+LOo+tOclUTemLfv5VVVVVfXeKNuwpT3qzn/fNVF3aZVtes3ijXQAAAAAACgwpAMAAAAAQIEhHQAAAAAACgzpAAAAAABQYEgHAAAAAIACQzoAAAAAABQY0gEAAAAAoMCQDgAAAAAABYZ0AAAAAAAoqDX7AlB/z7uj7pArboy6Y0b9OHzy8Kha2ftq1B159qlRN+6HC6IOGFx+8zddUXfLsbOjbmxr9hlVVS1RNX3u8Vl3wfzwuVVVj0t469S7to+6eTtfHJ7YHlXf/Jc/jbotq4H9PeDxfbPf7I6W7M+IOc9tG3WbXf2rqOuJKpqt4yd3R90NL7w76vZ42519uM1rLV27OuoOu/OTDX0uffe9nS6PumnDss/uL4x9IOqunLcq6q77yN5RV1VVVb87eza8ldo6t4q6Od+7LOqm1jqi7tHuV6Ju1tKZUVf/8vioa7v5rqjbosr+RmrdbpuoG3nxM1H3qy2vjLr0+2pPvTc8r6ruWdMddUdf/tmom/Sz7HO0qu4Pu+bwRjoAAAAAABQY0gEAAAAAoMCQDgAAAAAABYZ0AAAAAAAoMKQDAAAAAECBIR0AAAAAAAoM6QAAAAAAUGBIBwAAAACAAkM6AAAAAAAU1Jp9AQaf2haTou6p/baIuqvOOC/qOodtEHWpLz65S9Td+rXdom7cVQv6ch1ggHrp8Owz4PsfPTfqxrR2RF1vVY+6zuuPz7oTF0UdDFStHdnvzrL9R0bdpFp71K3qXRN1k2/MuoFu1ntuirqeevYZddmCvaOuc+XtUcfgUO/ujrqbz98j6r7+xWej7h9P/0DUbfBCdr9JP78z6njrfPjUU6PurlMubOhzPz76t1F38ftGx2dudve63gb6z4r9J0Td1Fr2vWzp2tVR95H/+/moG39Zurssj6q2cWOj7ulDOqPun8+YHXWTasOjrtFeqmf/f1RVVX34ulOibtrZ89f1OoOSN9IBAAAAAKDAkA4AAAAAAAWGdAAAAAAAKDCkAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgoNbsC9D/2jq3irpHj5gQdYcf9ouoO3PcvKjrrTaIupd6V0fdTtf+VdRtc8aDUTfmxQVRBwwutU0nRt3c886LujGtHX25zmt0/mhW1G190j1RV+/DXWAgWHLljKh7YO8LGvrcrl9+Ouqm/vzOhj634XZ9V5Ttv+EVUXfb6uFR1/mp26OOoWnjb2ffs+d9e2zUjagW9eU6DAJjlnQ3+wqwXnvfxxY29LynejaMuon/9Ouo6wmf27LDO6Luqf+zNuoW7nhR1LVWI6KuN/zr7CPL9ou6S96e7W8H3HtM1FVVVW1zzqNRN9Q+lb2RDgAAAAAABYZ0AAAAAAAoMKQDAAAAAECBIR0AAAAAAAoM6QAAAAAAUGBIBwAAAACAAkM6AAAAAAAUGNIBAAAAAKDAkA4AAAAAAAW1Zl+A1+rZe8eoG3fWo1F3xdu/E3XtLcOiLtcSVUvXro66o876XNRNv3xB1PVEFTDYrDpi96j71jnnRt3b2kZG3dp69qnSdffMqJsx+7mo61m7JupgIGrbtjNub93zwrBsX7fLvIHppz0bdd0NfWrjLTkx+543Y4PsPZsFr/blNgCDy+lP7xR1ky66Kz6zd10vA/1o7v07RN05E++Iuj07sm9IN938dNTd8oWuqJtwxsNRd8OUn0Vdum+1tWTfo3a544iom3BmW9T95cYnRd0mN+efUQP9u22zeCMdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFhnQAAAAAACgwpAMAAAAAQIEhHQAAAAAACmrNvsBQ8uLM3aPul1+9pMFP3qDB52XaWrL/TtM5rCPqVu71atSNvTzKgEFm+V93Rd11n5oddVNr2WdPT7036jqvPz7qtj1rRdR1L38s6mAw2+Jby+N2k7b2frzJGzv257dE3av1YVF3+k2HRl3HE9nX9KmXLIm643a4NepSx/74k1E3vVrU0OcC66e28eOjbvhnsu9Rjba6N/tM7n01+5sVBqr2R7LvW71VvaHPPX3cfVHXeuX9UZfeL/tLr6r+9pntou6GC98bdROvWxx1Pc88G3VtUUUjeCMdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFhnQAAAAAACgwpAMAAAAAQIEhHQAAAAAACmrNvsBQMuZfH4m6Dy4+KOoOnnBv1H3twX2irn7/qKib+g9PRd24q34XdVdOvinq5v3JJVF3StesqGuZn/38gP710uG7Rd3Ns2ZH3djW4X25zmtMn3t81HWeuCjquvtyGRgk2raeFnUfHjs3PrO1Se9/HDxyZUPP+/AHL23oecOOa4u6tfWe8MTs51xvqYfnAfz/PXxy9u+Nf9/mon6+CQxtU86/P+oO2uvPo+6H2/ygL9fpd196eoeou/fgyVE3dvmCqEu/lTHweCMdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFhnQAAAAAACgwpAMAAAAAQIEhHQAAAAAACmrNvsBQ0vPU01m4T5bNrcZH3RbVv2cHhnrC7u65XVl48k1RNin8p7V7RBYOy44D1tFLh+8WdV+fPSfqxrR2RN3C1VFWffTaT0fd9FMXZgcC/6XnoaVRd9I3jovPXD2uN+rG3d0Sn5noDb9/vP2YJQ19buoftvxJ1PVW2c8vddjut0fdfQ19KjDYtI3P/mb90VGzwxOHr/tlXsd3X3pb1D34mXdGXUt1Tx9uA8338t4zou5zk/++n2/SN113z4y6cTOfiLreVY/15TqsR7yRDgAAAAAABYZ0AAAAAAAoMKQDAAAAAECBIR0AAAAAAAoM6QAAAAAAUGBIBwAAAACAAkM6AAAAAAAUGNIBAAAAAKDAkA4AAAAAAAW1Zl+A9VdL18qGnre63ht1Hb99Pup6+nAXGMrW7rdz1M0977yoG9PaEXVP9LwSdUfPOzXqpp26MOqA/rPFWfObfYWGWfWNJj348cYet9e9M6Nu7HGvhic+tu6XAQa/1pYom1wb3s8XeX2nzz8k6jr/7c7+vQj0s8WX7Rp1yw7+etT1hPtMVWWfAam2lux94O3GrYi6x19Jv8/AH3gjHQAAAAAACgzpAAAAAABQYEgHAAAAAIACQzoAAAAAABQY0gEAAAAAoMCQDgAAAAAABYZ0AAAAAAAoMKQDAAAAAECBIR0AAAAAAApqzb7AQFXv2j7q3nvZovjMG898b9QNv+62+MxmaN1+RtT9605XhCd2RNWpjx0QdT2LHw6fC/x3tYkTom70mcuibmzr8KjrrepRd+CFp0XdtNnzow5gIGsbNaqh563qXRN1o/52ZNR1L1/al+sAAH20+PJd4vaeAy6Iup56e9Slf8Od/vROUXfS2F9G3aZtI6LuHRuuiLonN9026rqXPxZ1rP+8kQ4AAAAAAAWGdAAAAAAAKDCkAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFtWZfoFFa2tujbtmZO0bdT4+aHXWfWXZo1FVVVW1054qo645PbKzapM2jruWC56NuTOvwqHulvibqHj5/26jbsFoYdcD/66HzNo26X029MjyxJao6rz8+6raec0fU1aMKYGBrnTeyoeftc8cno26z+fc29LnA0Lb4/M2a8ty19Z6oG7Ek2xHgrbT48l2i7vY/mxOfOaKlYx1v8/o6f5D9DTdlXvbX2cZXNHbHuevFyVHXvfyxhj6X9Z830gEAAAAAoMCQDgAAAAAABYZ0AAAAAAAoMKQDAAAAAECBIR0AAAAAAAoM6QAAAAAAUGBIBwAAAACAAkM6AAAAAAAUGNIBAAAAAKCg1uwLNEp9h62j7sdHzo660a1tUffCVyZHXVVV1QbLb4/bRnr243tE3T4nLIy6syfcET65JarefcusqNvqu9n9gD969pPZ739VVdVDe10cltnv9vS5x0dd54mLoq4eVQADW9v0LaPutMnXNvS5I+aObuh5wNDW0t4edZPGPd+/F3kDL/SuibpJZ8/v55vAHz19YlfU3XPAuVE3oqWjL9d5XZ9a/t6oG7U4mxO/cNGVUdfeMizqXux9NeqWXDoj6jauFkQd/CdvpAMAAAAAQIEhHQAAAAAACgzpAAAAAABQYEgHAAAAAIACQzoAAAAAABQY0gEAAAAAoMCQDgAAAAAABYZ0AAAAAAAoMKQDAAAAAEBBrdkXaJSWOx6MugfXjou699dWRd3M82+IuqqqqgvfeUjU/X5KT9T99ft+EHVHjvpa1LWG/13lttUtUXfa4sOirvOE30Rd9lOBoeHlD+0Wdad9/pr4zN6qHnX73H941E0/cVH8bICh4pmuCVG3W/vaqOsNn9vanX3GAyRePGSHqPvFOy7u55u8vpm/PjLq2qtH+/ci8N/86TELo27DlvZ+vskbu3LyL6Ou5/O3NPjJ2c60370fi7pNrl7Qh7vAG/NGOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFhnQAAAAAACgwpAMAAAAAQIEhHQAAAAAACgzpAAAAAABQYEgHAAAAAIACQzoAAAAAABQY0gEAAAAAoKDW7As0Sr27O+rOOeXoqNvlkvOj7phRy6OuqqrqmFMujNvGyv57yaFLD4y6FVdPjbqxVyyIup6ogqGhZdgGUbf555ZE3V+MfC5+9sxH9o+6UTNXRp3fbYD+d/pTu0bdqGsW9vNNgKHk+enNeSdv8do1Ubf2iolR11492ofbwJuz56jFUddb1fv5JgX13ihL73jjKyOj7oxzj4m68ZdmOxP0F2+kAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFhnQAAAAAACgwpAMAAAAAQEGt2Rd4q3Vcf1vUHbHm5Kg77mvfj5996IbPxG1i5iP7R92dD2wZdTNO+3XUjX1xQdQBb17vzjOi7uop34i6y57Pfv+rqqpe/vjoqOtZ+XB8JgD964c/2CPqJlfz+/kmwFBy9ke/3ZTn/t0T2d/AG353YT/fBN68s75yVNR9YavsvNbOl+Jn/8nkR7IzW3qj7qcPbht12/zdi1E3/ld2JgYHb6QDAAAAAECBIR0AAAAAAAoM6QAAAAAAUGBIBwAAAACAAkM6AAAAAAAUGNIBAAAAAKDAkA4AAAAAAAWGdAAAAAAAKDCkAwAAAABAQa3ZFxioNvjJHVH3za3fHp/5zSpvM89EVWfY9fTlKsCAdNV5H4jbsYsX9ONNAOgPUy9+KOp8zwOA5trkG9nfW5v0w7N/2+Dzpld3Rp3vH6xvvJEOAAAAAAAFhnQAAAAAACgwpAMAAAAAQIEhHQAAAAAACgzpAAAAAABQYEgHAAAAAIACQzoAAAAAABQY0gEAAAAAoMCQDgAAAAAABbVmXwCAP2pZcG/UHbT5TlE3tlrQl+sA0GBjrso+lw++apfwxGfX/TIAg8yy2TOibkS1qJ9vAsBQ5I10AAAAAAAoMKQDAAAAAECBIR0AAAAAAAoM6QAAAAAAUGBIBwAAAACAAkM6AAAAAAAUGNIBAAAAAKDAkA4AAAAAAAWGdAAAAAAAKKg1+wIAAADA4PG5G46MugMPvzjq/mLJQVG30a2PRF1PVAHAm+ONdAAAAAAAKDCkAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFBjSAQAAAACgwJAOAAAAAAAFhnQAAAAAACioNfsCAAAAwOAx7bMLo+6gz+4UnvjEul8GAN4i3kgHAAAAAIACQzoAAAAAABQY0gEAAAAAoMCQDgAAAAAABYZ0AAAAAAAoMKQDAAAAAECBIR0AAAAAAAoM6QAAAAAAUGBIBwAAAACAgpZ6vV5v9iUAAAAAAGCg8kY6AAAAAAAUGNIBAAAAAKDAkA4AAAAAAAWGdAAAAAAAKDCkAwAAAABAgSEdAAAAAAAKDOkAAAAAAFBgSAcAAAAAgAJDOgAAAAAAFPwHeO/RtoYEaQoAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1500x1500 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_generator = ImageDataGenerator(rescale=1./255) \n",
        "data_gen = image_generator.flow(x_train, y_train, batch_size=32) \n",
        "sample_images, sample_labels = next(data_gen)\n",
        "plotImages(sample_images[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8bStvJVoVlj"
      },
      "source": [
        "One regularisation method to deal with over-fitting is data augmentation. The image generator can apply various transformations to data - here we apply a random rotation of upto 20 degrees and visualise the same training example with different augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "iz28zlncmIiP",
        "outputId": "079fa9d6-0ba7-45a8-d9eb-4ec24a66d089"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1500 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_generator = ImageDataGenerator(rescale=1/255, \n",
        "                                     rotation_range=20) \n",
        "data_gen = image_generator.flow(x_train, y_train, batch_size=32) \n",
        "augmented_images = [data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIE6-wlA3J4h"
      },
      "source": [
        "Define a basic CNN with 32 convolutional filters using a 3x3 kernel, followed by a dense fully connected layer of 128 units and an output layer of 10 units with softmax activation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKolHZQUL8-4"
      },
      "outputs": [],
      "source": [
        "'''''\n",
        "class BasicCNN(Model):\n",
        "  def __init__(self):\n",
        "    super(BasicCNN, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu',  kernel_regularizer=regularizers.L1(0.01))\n",
        "    self.flatten = Flatten()\n",
        "    self.drop1 = Dropout(rate=0.2)\n",
        "    self.dense1 = Dense(128, activation='relu', kernel_regularizer=regularizers.L2(0.01))\n",
        "    self.drop2 = Dropout(rate=0.2)\n",
        "    self.dense2 = Dense(10, activation='softmax',  kernel_regularizer=regularizers.L2(0.01))\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.drop1(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.drop2(x)\n",
        "    x = self.dense2(x)\n",
        "    return x\n",
        "'''''\n",
        "\n",
        "class BasicCNN(Model):\n",
        "  def __init__(self):\n",
        "    super(BasicCNN, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu', kernel_regularizer=regularizers.l2(0.01))\n",
        "    self.conv2 = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01))\n",
        "    self.drop1 = Dropout(0.25)\n",
        "    self.flatten = Flatten()\n",
        "    self.batch1 = keras.layers.BatchNormalization()\n",
        "    self.d1 = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))\n",
        "    self.drop2 = Dropout(0.25)\n",
        "    self.batch2 = keras.layers.BatchNormalization()\n",
        "    self.d2 = Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.01))\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.drop1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.batch1(x)\n",
        "    x = self.d1(x)\n",
        "    x = self.drop2(x)\n",
        "    x = self.batch2(x)\n",
        "    return self.d2(x)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuhNDi134B2G"
      },
      "source": [
        "Main training routine - uses the more detailed Gradient Tape API to iterate over the dataset and update the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "MZH8jdqKohiU"
      },
      "outputs": [],
      "source": [
        "def trainer(cls, train_image_generator, test_image_generator, \n",
        "            verbose=False, batch_size=32, max_epochs=5):\n",
        "  \n",
        "  model = cls()\n",
        "\n",
        "  train_data_gen = train_image_generator.flow(x_train, y_train, \n",
        "                                              batch_size=batch_size) \n",
        "\n",
        "  test_data_gen = test_image_generator.flow(x_test, y_test, \n",
        "                                              batch_size=batch_size) \n",
        "\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')\n",
        "\n",
        "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='test_accuracy')\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = model(images, training=True)\n",
        "      loss = loss_object(labels, predictions) \n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "  @tf.function\n",
        "  def test_step(images, labels):\n",
        "    predictions = model(images, training=False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    # Reset the metrics at the start of the next epoch\n",
        "    train_loss.reset_state()\n",
        "    train_accuracy.reset_state()\n",
        "    test_loss.reset_state()\n",
        "    test_accuracy.reset_state()\n",
        "\n",
        "    batches = 0\n",
        "    for images, labels in train_data_gen:\n",
        "      train_step(images, labels)\n",
        "      batches += 1\n",
        "      if batches >= len(x_train) / batch_size:\n",
        "        break\n",
        "\n",
        "    batches = 0\n",
        "    for images, labels in test_data_gen:\n",
        "      test_step(images, labels)\n",
        "      batches += 1\n",
        "      if batches >= len(x_test) / batch_size:\n",
        "        break\n",
        "\n",
        "    if verbose:\n",
        "      template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "      print(template.format(epoch+1,\n",
        "                            train_loss.result(),\n",
        "                            train_accuracy.result()*100,\n",
        "                            test_loss.result(),\n",
        "                            test_accuracy.result()*100))\n",
        "    \n",
        "  return test_loss.result().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBSBEZftgDsL"
      },
      "source": [
        "Baseline run with no regularisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkemC6SvTLOH",
        "outputId": "6a9f1162-25a7-490a-c899-1e84b915da4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.2269399166107178, Accuracy: 59.39999771118164, Test Loss: 0.5008776187896729, Test Accuracy: 84.83000183105469\n",
            "Epoch 2, Loss: 0.4814055562019348, Accuracy: 86.5999984741211, Test Loss: 0.29622629284858704, Test Accuracy: 90.62000274658203\n",
            "Epoch 3, Loss: 0.3033866584300995, Accuracy: 91.0999984741211, Test Loss: 0.20794834196567535, Test Accuracy: 93.33000183105469\n",
            "Epoch 4, Loss: 0.19600313901901245, Accuracy: 93.9000015258789, Test Loss: 0.2275959998369217, Test Accuracy: 92.95999908447266\n",
            "Epoch 5, Loss: 0.14279109239578247, Accuracy: 95.5, Test Loss: 0.2346668243408203, Test Accuracy: 93.18000030517578\n",
            "Epoch 6, Loss: 0.11849255859851837, Accuracy: 96.10000610351562, Test Loss: 0.2274332493543625, Test Accuracy: 93.37999725341797\n",
            "Epoch 7, Loss: 0.11117909103631973, Accuracy: 96.5999984741211, Test Loss: 0.21406947076320648, Test Accuracy: 94.02999877929688\n",
            "Epoch 8, Loss: 0.10491674393415451, Accuracy: 96.80000305175781, Test Loss: 0.17860354483127594, Test Accuracy: 94.68000030517578\n",
            "Epoch 9, Loss: 0.06701156497001648, Accuracy: 97.79999542236328, Test Loss: 0.18285496532917023, Test Accuracy: 95.01000213623047\n",
            "Epoch 10, Loss: 0.07369856536388397, Accuracy: 98.0, Test Loss: 0.1973784863948822, Test Accuracy: 94.52999877929688\n",
            "Epoch 11, Loss: 0.06000588461756706, Accuracy: 98.69999694824219, Test Loss: 0.22870662808418274, Test Accuracy: 94.05999755859375\n",
            "Epoch 12, Loss: 0.04813005030155182, Accuracy: 98.5, Test Loss: 0.22830694913864136, Test Accuracy: 93.87999725341797\n",
            "Epoch 13, Loss: 0.04263238236308098, Accuracy: 98.4000015258789, Test Loss: 0.2514117360115051, Test Accuracy: 94.05000305175781\n",
            "Epoch 14, Loss: 0.043339990079402924, Accuracy: 98.29999542236328, Test Loss: 0.21142888069152832, Test Accuracy: 94.4800033569336\n",
            "Epoch 15, Loss: 0.026521701365709305, Accuracy: 99.0999984741211, Test Loss: 0.21716725826263428, Test Accuracy: 94.75\n",
            "Epoch 16, Loss: 0.04349696636199951, Accuracy: 98.79999542236328, Test Loss: 0.20664912462234497, Test Accuracy: 94.83000183105469\n",
            "Epoch 17, Loss: 0.0384620763361454, Accuracy: 98.19999694824219, Test Loss: 0.22272272408008575, Test Accuracy: 94.7300033569336\n",
            "Epoch 18, Loss: 0.04154462367296219, Accuracy: 98.5, Test Loss: 0.19787849485874176, Test Accuracy: 94.91999816894531\n",
            "Epoch 19, Loss: 0.024044964462518692, Accuracy: 99.5, Test Loss: 0.1959027200937271, Test Accuracy: 95.0999984741211\n",
            "Epoch 20, Loss: 0.02381547912955284, Accuracy: 99.19999694824219, Test Loss: 0.2214217483997345, Test Accuracy: 94.77000427246094\n",
            "Final test loss: 0.22142175\n"
          ]
        }
      ],
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255, rotation_range=20) \n",
        "test_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "final_test_loss = trainer(BasicCNN, train_image_generator, test_image_generator, \n",
        "                          verbose=True, max_epochs=20)\n",
        "print('Final test loss:', final_test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.117375373840332, Accuracy: 64.20000457763672, Test Loss: 0.4880084991455078, Test Accuracy: 85.97000122070312\n",
            "Epoch 2, Loss: 0.4695412516593933, Accuracy: 84.79999542236328, Test Loss: 0.34091341495513916, Test Accuracy: 89.70000457763672\n",
            "Epoch 3, Loss: 0.32577481865882874, Accuracy: 90.5, Test Loss: 0.2669074237346649, Test Accuracy: 91.54000091552734\n",
            "Epoch 4, Loss: 0.24515850841999054, Accuracy: 92.5999984741211, Test Loss: 0.19035600125789642, Test Accuracy: 93.9000015258789\n",
            "Epoch 5, Loss: 0.165800541639328, Accuracy: 95.0, Test Loss: 0.18886815011501312, Test Accuracy: 94.25\n",
            "Epoch 6, Loss: 0.13095764815807343, Accuracy: 95.5, Test Loss: 0.20691563189029694, Test Accuracy: 93.81999969482422\n",
            "Epoch 7, Loss: 0.11218482255935669, Accuracy: 96.20000457763672, Test Loss: 0.1648080050945282, Test Accuracy: 95.12000274658203\n",
            "Epoch 8, Loss: 0.09514801949262619, Accuracy: 97.19999694824219, Test Loss: 0.18153291940689087, Test Accuracy: 94.81999969482422\n",
            "Epoch 9, Loss: 0.06560531258583069, Accuracy: 98.0, Test Loss: 0.2082696557044983, Test Accuracy: 94.19000244140625\n",
            "Epoch 10, Loss: 0.08582479506731033, Accuracy: 97.0999984741211, Test Loss: 0.18239432573318481, Test Accuracy: 94.81999969482422\n",
            "Epoch 11, Loss: 0.05798869580030441, Accuracy: 98.0999984741211, Test Loss: 0.21735523641109467, Test Accuracy: 94.5999984741211\n",
            "Epoch 12, Loss: 0.056028395891189575, Accuracy: 98.0, Test Loss: 0.16924692690372467, Test Accuracy: 95.29000091552734\n",
            "Epoch 13, Loss: 0.06917332112789154, Accuracy: 97.69999694824219, Test Loss: 0.20992788672447205, Test Accuracy: 94.77999877929688\n",
            "Epoch 14, Loss: 0.04226753115653992, Accuracy: 98.5, Test Loss: 0.1767004281282425, Test Accuracy: 95.1500015258789\n",
            "Epoch 15, Loss: 0.03454264625906944, Accuracy: 99.0999984741211, Test Loss: 0.20326665043830872, Test Accuracy: 95.04000091552734\n",
            "Epoch 16, Loss: 0.03769788518548012, Accuracy: 98.9000015258789, Test Loss: 0.18662983179092407, Test Accuracy: 95.45000457763672\n",
            "Epoch 17, Loss: 0.04240964353084564, Accuracy: 98.69999694824219, Test Loss: 0.19247926771640778, Test Accuracy: 95.16000366210938\n",
            "Epoch 18, Loss: 0.029321132227778435, Accuracy: 98.9000015258789, Test Loss: 0.22246494889259338, Test Accuracy: 94.54000091552734\n",
            "Epoch 19, Loss: 0.02905845455825329, Accuracy: 99.0, Test Loss: 0.24403852224349976, Test Accuracy: 94.84000396728516\n",
            "Epoch 20, Loss: 0.032676104456186295, Accuracy: 98.79999542236328, Test Loss: 0.20482759177684784, Test Accuracy: 95.12000274658203\n",
            "Final test loss: 0.20482759\n"
          ]
        }
      ],
      "source": [
        "#0.01 L2 regularization\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255, rotation_range=20) \n",
        "test_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "final_test_loss = trainer(BasicCNN, train_image_generator, test_image_generator, \n",
        "                          verbose=True, max_epochs=20)\n",
        "print('Final test loss:', final_test_loss)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM22uAKlWUTfo8m5mjrvkMz",
      "include_colab_link": true,
      "name": "regularisation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MLE",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
